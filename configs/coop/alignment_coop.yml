model:
  latent_dim: 2048
  proj_dropout: 0.1
  linear_projection: true
  model_path: "roberta-large"
  model_arch: "roberta"
  encoder_type: "SumTextEncoder"
  momentum: 0.0
  device: "cuda"
  labels: ['neutral', 'good', 'evil']

train_job:
  n_ctx: 512
  epochs: 30
  batch_size: 256
  microbatch_size: 256
  lr_ramp_steps: 50
  lr_decay_steps: 3366
  learning_rate_init: 5.0e-5
  learning_rate_target: 0.000006
  log_interval: 25
  checkpoint_interval: 500
  validate_interval: 30
  use_half: false
  do_log: true
  validation_size: 32
  eval_selection: "final_n"
  use_bucket: false
  dupe_protection: true
  hard_dupe_protection: false
  data_pipeline: "AlignmentDataPipeline"
  trainer: "CARPCoOpTrainer"
  gradient_checkpointing: true
  grad_clip: -1.0
  grad_accum: 2
  temp: .2
  save_folder: 'alignment/'
  save_best_val: False
  save_at_end: True